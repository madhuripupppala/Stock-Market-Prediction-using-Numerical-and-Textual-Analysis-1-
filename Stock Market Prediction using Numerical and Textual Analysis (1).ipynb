{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intern @GRIP Spark Foundation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# madhuri jaya bhaskarni puppala\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Market Prediction using Numerical and Textual Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import lag_plot\n",
    "from datetime  import datetime\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from pmdarima.arima import auto_arima\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error\n",
    "from math import sqrt\n",
    "import joblib\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install pmdarima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## We will analyze the last 15 years stock price data of BSE Sensex\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\jayar\\Documents\\maa\\historica_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df['Date'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('Date',inplace=True,drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using ARIMA Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Checking for Cross-correlation\n",
    "\n",
    "plt.figure()\n",
    "lag_plot(df['Close'], lag=3)\n",
    "plt.title('BSE Sensex - Autocorrelation plot with lag = 3')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There is an auto correlation for lag=3 (i.e the data of current day is correlated to previous 3 days' data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "plt.plot(df[\"Close\"])\n",
    "plt.title(\"BSE Sensex stock price over time\")\n",
    "plt.xlabel(\"time\")\n",
    "plt.ylabel(\"price\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into train and training set\n",
    "\n",
    "train_data, test_data = df[:int(len(df)*0.9)], df[int(len(df)*0.9):]\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.grid(True)\n",
    "plt.xlabel('Dates')\n",
    "plt.ylabel('Closing Prices')\n",
    "plt.plot(df['Close'], 'green', label='Train data')\n",
    "plt.plot(test_data['Close'], 'blue', label='Test data')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The auto_arima function seeks to identify the \n",
    "# most optimal parameters for an ARIMA model, and returns a fitted ARIMA model. \n",
    "\n",
    "model_autoARIMA = auto_arima(train_data['Close'], start_p=0, start_q=0,\n",
    "                      test='adf',       # use adftest to find             optimal 'd'\n",
    "                      max_p=3, max_q=3, # maximum p and q\n",
    "                      m=1,              # frequency of series\n",
    "                      d=None,           # let model determine 'd'\n",
    "                      seasonal=False,   # No Seasonality\n",
    "                      start_P=0, \n",
    "                      D=0, \n",
    "                      trace=True,\n",
    "                      error_action='ignore',  \n",
    "                      suppress_warnings=True, \n",
    "                      stepwise=True)\n",
    "print(model_autoARIMA.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the ARIMA model\n",
    "\n",
    "model = ARIMA(train_data['Close'], order=(0,1,1))  \n",
    "fitted = model.fit(disp=-1)  \n",
    "print(fitted.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecast\n",
    "\n",
    "fc, se, conf = fitted.forecast(368, alpha=0.05)  # 95% confidence\n",
    "fc_series = pd.Series(fc, index=test_data.index)\n",
    "lower_series = pd.Series(conf[:, 0], index=test_data.index)\n",
    "upper_series = pd.Series(conf[:, 1], index=test_data.index)\n",
    "plt.figure(figsize=(12,5), dpi=100)\n",
    "plt.plot(train_data['Close'], label='training')\n",
    "plt.plot(test_data['Close'], color = 'blue', label='Actual Stock Price')\n",
    "plt.plot(fc_series, color = 'orange',label='Predicted Stock Price')\n",
    "plt.fill_between(lower_series.index, lower_series, upper_series, \n",
    "                 color='k', alpha=.10)\n",
    "plt.title('BSE Sensex Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Actual Stock Price')\n",
    "plt.legend(loc='upper left', fontsize=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report performance\n",
    "mse = mean_squared_error(test_data['Close'], fc)\n",
    "print('MSE: '+str(mse))\n",
    "mae = mean_absolute_error(test_data['Close'], fc)\n",
    "print('MAE: '+str(mae))\n",
    "rmse = sqrt(mean_squared_error(test_data['Close'], fc))\n",
    "print('RMSE: '+str(rmse))\n",
    "mape = np.mean(np.abs(fc - test_data['Close'])/np.abs(test_data['Close']))\n",
    "print('MAPE: '+str(mape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Around 7.6% MAPE(Mean Absolute Percentage Error) implies the model is about 92.4% accurate in predicting the test set observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using LSTM Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock1 = df[\"Close\"].copy()\n",
    "stock1 = pd.DataFrame(stock1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "df1 = scaler.fit_transform(stock1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train test split\n",
    "\n",
    "train_size = int(len(df1)*0.9)\n",
    "test_size = len(df1) - train_size\n",
    "initial_train_data,test_data=df1[0:train_size,:],df1[train_size:len(df1),:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size,test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Validation Data\n",
    "\n",
    "train_data,cv_data = initial_train_data[0:int(len(initial_train_data)*0.8)],initial_train_data[int(len(initial_train_data)*0.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, time_step=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-time_step-1):\n",
    "        a = dataset[i:(i+time_step), 0]   \n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + time_step, 0])\n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_step = 60\n",
    "Xtrain, ytrain = create_dataset(train_data, time_step)\n",
    "Xtest, ytest = create_dataset(test_data, time_step)\n",
    "Xcv,ycv = create_dataset(cv_data, time_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Xtrain.shape), print(ytrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Xtest.shape), print(ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape input to be [samples, time steps, features] which is required for LSTM\n",
    "Xtrain =Xtrain.reshape(Xtrain.shape[0],Xtrain.shape[1] , 1)\n",
    "Xtest = Xtest.reshape(Xtest.shape[0],Xtest.shape[1] , 1)\n",
    "Xcv = Xcv.reshape(Xcv.shape[0],Xcv.shape[1] , 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Create the Stacked LSTM model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining our metric\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LSTM Model Initialization\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=128, activation='tanh', kernel_initializer=tf.keras.initializers.glorot_uniform(seed=26), input_shape = (Xtrain.shape[1], 1), unroll = True))\n",
    "model.add(Dense(1, name=\"output_layer\"))\n",
    "model.compile(optimizer = Adam(learning_rate=0.001), loss = root_mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(Xtrain,ytrain,validation_data=(Xcv,ycv),epochs=100,batch_size=16,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prediction and check performance metrics\n",
    "train_predict=model.predict(Xtrain)\n",
    "test_predict=model.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Transform back to original form\n",
    "train_predict=scaler.inverse_transform(train_predict)\n",
    "test_predict=scaler.inverse_transform(test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rescaled_ytrain = scaler.inverse_transform(ytrain.reshape(-1, 1))\n",
    "rescaled_ytest = scaler.inverse_transform(ytest.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate RMSE performance metrics\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "math.sqrt(mean_squared_error(rescaled_ytrain,train_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report performance\n",
    "mse = mean_squared_error(rescaled_ytest,test_predict)\n",
    "print('MSE: '+str(mse))\n",
    "mae = mean_absolute_error(rescaled_ytest,test_predict)\n",
    "print('MAE: '+str(mae))\n",
    "rmse = math.sqrt(mean_squared_error(rescaled_ytest,test_predict))\n",
    "print('RMSE: '+str(rmse))\n",
    "mape = np.mean(np.abs(test_predict - rescaled_ytest)/np.abs(rescaled_ytest))\n",
    "print('MAPE: '+str(mape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "plt.plot(scaler.inverse_transform(df1[3363:,]),color='red', label='Actual Price')\n",
    "plt.plot(test_predict, color='blue', linestyle='dashed',label='Predicted Price')\n",
    "plt.title('BSE Sensex Prices Prediction - LSTM Model')\n",
    "plt.ylabel('Prices')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations:\n",
    "\n",
    "### It seems that there has been a great fall in stock market price in the time period of March 2020 - May 2020. This is mainly due to lockdown announcement made by Indian Government in March 2020 due to COVID-19. So we will target the time period of 30-06-2019 to 29-06-2020 in this task.\n",
    "### So, the prediction models results in error during this time period. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = pd.read_csv(\"india-news-headlines.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text['publish_date'] = pd.to_datetime(text['publish_date'],format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since, we only have the the numerical data between 30-06-2005 to 29-06-2020, we will only use the text data generated during these dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = text[text['publish_date']> '2005-06-29'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since, we are doing a stock price prediction, we only need data related to business"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headline_cats = [cat for cat in text1['headline_category'].value_counts().index if 'business' in cat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headline_cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = text1.loc[text1['headline_category'].str.find('business') !=-1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining the rows of the same date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = text1.groupby('publish_date').agg({'headline_category':'first','headline_text': '. '.join}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2['headline_text'] = text2['headline_text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for text in text2['headline_text']:\n",
    "    if 'bse' in text or 'sensex' in text :\n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sensex or BSE occurs 3396 times in the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize\n",
    "\n",
    "def actual_news(data):\n",
    "    for index in data.index:\n",
    "        sentences = sent_tokenize(data['headline_text'][index])\n",
    "        relevant_line = ' '.join(sent for sent in sentences if 'sensex' in sent or 'bse' in sent)\n",
    "        if len(relevant_line)>5:\n",
    "            data['headline_text'][index] =relevant_line\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text3 = actual_news(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the text\n",
    "from nltk import word_tokenize\n",
    "\n",
    "def clean_txt(text):\n",
    "    # Removing non alphanumeric text\n",
    "    text = re.sub('[^a-zA-Z]',' ',text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1['headline_text'] = text1['headline_text'].apply(clean_txt)\n",
    "text3['headline_text'] = text3['headline_text'].apply(clean_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines = list(text1['headline_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment Analysis\n",
    "\n",
    "score=[]\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stock Market Lexicon to update the sentiment analyzer to analyze business news\n",
    "import csv\n",
    "\n",
    "stock_lex = pd.read_csv('lexicon_data/stock_lex.csv')\n",
    "stock_lex['sentiment'] = (stock_lex['Aff_Score'] + stock_lex['Neg_Score'])/2\n",
    "stock_lex = dict(zip(stock_lex.Item, stock_lex.sentiment))\n",
    "stock_lex = {k:v for k,v in stock_lex.items() if len(k.split(' '))==1}\n",
    "stock_lex_scaled = {}\n",
    "for k, v in stock_lex.items():\n",
    "    if v > 0:\n",
    "        stock_lex_scaled[k] = v / max(stock_lex.values()) * 4\n",
    "    else:\n",
    "        stock_lex_scaled[k] = v / min(stock_lex.values()) * -4\n",
    "\n",
    "# Loughran and McDonald\n",
    "positive = []\n",
    "with open('lexicon_data/lm_positive.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        positive.append(row[0].strip())\n",
    "    \n",
    "negative = []\n",
    "with open('lexicon_data/lm_negative.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        entry = row[0].strip().split(\" \")\n",
    "        if len(entry) > 1:\n",
    "            negative.extend(entry)\n",
    "        else:\n",
    "            negative.append(entry[0])\n",
    "\n",
    "final_lex = {}\n",
    "final_lex.update({word:2.0 for word in positive})\n",
    "final_lex.update({word:-2.0 for word in negative})\n",
    "final_lex.update(stock_lex_scaled)\n",
    "final_lex.update(sid.lexicon)\n",
    "sid.lexicon = final_lex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the sentiment of each headline\n",
    "\n",
    "scores = []\n",
    "\n",
    "for sentence in headlines:\n",
    "    scores.append(sid.polarity_scores(sentence)['compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will create a classification model to identify whether the news is positive or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the word vectorizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,3),lowercase=False)\n",
    "# vectorizer = joblib.load('TF-IDF Vectorizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Xtrain,Xtest,ytrain,ytest = train_test_split(headlines[int(len(headlines)/2):],scores[int(len(headlines)/2):],test_size=0.25,random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = vectorizer.fit_transform(Xtrain)\n",
    "Xtest = vectorizer.transform(Xtest)\n",
    "\n",
    "# Xtrain = vectorizer.transform(Xtrain)\n",
    "# Xtest = vectorizer.transform(Xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "naive = MultinomialNB()\n",
    "naive.fit(Xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediciton = naive.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n",
    "\n",
    "matrix = confusion_matrix(ytest,prediciton)\n",
    "print(matrix)\n",
    "print('The model accuracy is {}'.format(round(accuracy_score(ytest,prediciton),3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "# model = svm.SVC(C=100,kernel='rbf',gamma=0.01)\n",
    "model = joblib.load('SVM_classifier_text')\n",
    "# model.fit(Xtrain, ytrain) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(Xtest)\n",
    "matrix = confusion_matrix(ytest,predictions)\n",
    "print(matrix)\n",
    "print('The model accuracy is {}'.format(round(accuracy_score(ytest,predictions),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.dump(model,'SVM_classifier_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.dump(vectorizer,'TF-IDF Vectorizer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# cf = RandomForestClassifier(n_estimators=100,criterion='entropy')\n",
    "cf = joblib.load('RF_classifier_text')\n",
    "# cf.fit(Xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = cf.predict(Xtest)\n",
    "matrix = confusion_matrix(ytest,predictions)\n",
    "print(matrix)\n",
    "print('The model accuracy is {}'.format(round(accuracy_score(ytest,predictions),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.dump(cf,'RF_classifier_text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Classifier gives the best result among all other classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "print(Counter(scores).keys())\n",
    "print(Counter(scores).values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's focus on the keywords which have been used the targeted time period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_news = text3.loc[text3['publish_date']>'2019-06-29']\n",
    "target_news1 = text2.loc[text2['publish_date']>'2019-06-29']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS \n",
    "stopwords = set(STOPWORDS)\n",
    "\n",
    "news_tokens = ''\n",
    "news_tokens1 = ''\n",
    "for index in target_news.index:\n",
    "        news_tokens = news_tokens + '. ' + target_news['headline_text'][index]\n",
    "        \n",
    "for index in target_news1.index:\n",
    "        news_tokens1 = news_tokens1 + '. ' + target_news1['headline_text'][index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a WordCloud\n",
    "\n",
    "wordcloud = WordCloud(width = 800, height = 800, \n",
    "                background_color ='white', \n",
    "                stopwords = stopwords, \n",
    "                min_font_size = 10).generate(news_tokens)\n",
    "\n",
    "wordcloud1 = WordCloud(width = 800, height = 800, \n",
    "                background_color ='white', \n",
    "                stopwords = stopwords, \n",
    "                min_font_size = 10).generate(news_tokens1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Before extracting the BSE Sensex related texts\n",
    "\n",
    "plt.figure(figsize = (5, 5), facecolor = None) \n",
    "plt.imshow(wordcloud1) \n",
    "plt.axis(\"off\") \n",
    "plt.tight_layout(pad = 0) \n",
    "  \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## After extracting the BSE Sensex related texts\n",
    "\n",
    "plt.figure(figsize = (5, 5), facecolor = None) \n",
    "plt.imshow(wordcloud) \n",
    "plt.axis(\"off\") \n",
    "plt.tight_layout(pad = 0) \n",
    "  \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation: We can see the top words used in the news data during the targeted time period. \n",
    "### High usage of terms like 'covid','plan' ,'seek','cut','hit' gives us an insight of the companies strategies.\n",
    "### Also, if compare the texts before extracting Sensex related news, there  isn't much clarity on the important words whereas extracting Sensex related news in a much more clear view of the keywords used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Hybrid Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will add the sentiment of the texts to the original LSTM and see if there is an imporvement in the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now let's join the text data to original data\n",
    "\n",
    "hybrid_data = pd.merge(left=df,right=text3,left_on=df['Date'],right_on=text3['publish_date'],how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking only the necessary columns\n",
    "\n",
    "hybrid_data = hybrid_data[['Date','Close','headline_text']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Headlines\n",
    "\n",
    "headlines = hybrid_data['headline_text'].apply('. '.join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment Score\n",
    "\n",
    "scores = []\n",
    "\n",
    "for sentence in headlines:\n",
    "    sentiment = scores.append(sid.polarity_scores(sentence)['compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_data['Sentiment'] = np.array(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blending the results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_data = hybrid_data[[\"Close\",\"Sentiment\"]].copy()\n",
    "stock_data = pd.DataFrame(stock_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train Test Split\n",
    "train_data, test_data = stock_data[0:int(len(stock_data)*0.8)], stock_data[int(len(stock_data)*0.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size,test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train and Validation data split\n",
    "\n",
    "Xtrain, Xcv = train_data[0:int(len(train_data)*0.8)], train_data[int(len(train_data)*0.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating the dataset\n",
    "\n",
    "def create_dataset(dataset, scoreset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back), 0]\n",
    "        b = scoreset[i+look_back-1]\n",
    "        dataX.append(np.append(a,b))\n",
    "        dataY.append(dataset[i + look_back, 0])\n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scaling the values\n",
    "\n",
    "train_data_close = scaler.transform(Xtrain['Close'].values.reshape(-1,1))\n",
    "test_data_close = scaler.transform(test_data['Close'].values.reshape(-1, 1))\n",
    "cv_data_close = scaler.transform(Xcv['Close'].values.reshape(-1,1))\n",
    "\n",
    "train_data_senti = scaler.transform(Xtrain['Sentiment'].values.reshape(-1,1))\n",
    "test_data_senti = scaler.transform(test_data['Sentiment'].values.reshape(-1, 1))\n",
    "cv_data_senti = scaler.transform(Xcv['Sentiment'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model the data\n",
    "\n",
    "time_step = 60\n",
    "Xtrain, ytrain = create_dataset(train_data_close,train_data_senti, time_step)\n",
    "Xtest, ytest = create_dataset(test_data_close,test_data_senti, time_step)\n",
    "Xcv,ycv = create_dataset(cv_data_close,cv_data_senti, time_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Xtrain.shape), print(ytrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape input to be [samples, time steps, features] which is required for LSTM\n",
    "\n",
    "trainX, trainY = np.array(Xtrain), np.array(ytrain)\n",
    "trainX = np.reshape(Xtrain, (Xtrain.shape[0], Xtrain.shape[1], 1))\n",
    "\n",
    "cvX, cvY = np.array(Xcv), np.array(ycv)\n",
    "cvX = np.reshape(Xcv, (Xcv.shape[0], Xcv.shape[1], 1))\n",
    "\n",
    "testX, testY = np.array(Xtest), np.array(ytest)\n",
    "testX = np.reshape(Xtest, (Xtest.shape[0], Xtest.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create the LSTM model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining our metric\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_model = Sequential()\n",
    "hybrid_model.add(LSTM(units=128, activation='tanh', kernel_initializer=tf.keras.initializers.glorot_uniform(seed=26), input_shape = (trainX.shape[1], 1), unroll = True))\n",
    "hybrid_model.add(Dense(1, name=\"output_layer\"))\n",
    "hybrid_model.compile(optimizer = Adam(learning_rate=0.001), loss = root_mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_model.fit(trainX,trainY,validation_data=(cvX,cvY),epochs=100,batch_size=16,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prediction and check performance metrics\n",
    "train_predict=hybrid_model.predict(trainX)\n",
    "test_predict=hybrid_model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Transform back to original form\n",
    "train_predict=scaler.inverse_transform(train_predict)\n",
    "test_predict=scaler.inverse_transform(test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rescaled_ytrain = scaler.inverse_transform(trainY.reshape(-1, 1))\n",
    "rescaled_ytest = scaler.inverse_transform(testY.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report performance\n",
    "mse = mean_squared_error(rescaled_ytest,test_predict)\n",
    "print('MSE: '+str(mse))\n",
    "mae = mean_absolute_error(rescaled_ytest,test_predict)\n",
    "print('MAE: '+str(mae))\n",
    "rmse = sqrt(mean_squared_error(rescaled_ytest,test_predict))\n",
    "print('RMSE: '+str(rmse))\n",
    "mape = np.mean(np.abs(test_predict - rescaled_ytest)/np.abs(rescaled_ytest))\n",
    "print('MAPE: '+str(mape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion: With the help of sentiment analyzed from data, we were able to get a better result than the a individual LSTM model. The performance improvement is marginally significant indicating a small but considerable effect of news data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the models for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(sid,'Sentiment Analyzer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = hybrid_model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "hybrid_model.save_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(scaler,'MinMaxScaler')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
